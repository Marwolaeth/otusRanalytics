---
title: "Howework 5_1"
author: "Andrej Pawluczenko"
date: '24 ноября 2019 г '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*Установка и загрузка библиотек:*

```{r packages_load, message=FALSE, warning=FALSE}
if(!require('pacman')) install.packages('pacman')
pacman::p_load(
  checkpoint,
  tidyverse,
  forcats,
  stringr,
  readr,
  dlookr,
  tree,
  rpart,
  rpart.plot,
  rattle,
  ModelMetrics
)

# checkpoint('2019-11-24')
```



## Данные

### Общая информация

В качестве учебного примера мы используем [набор](http://archive.ics.uci.edu/ml/datasets/Bank+Marketing) данных по банковскому телемаркетингу, предоставленные одним из португальских банков в 2012 г.

Одна из причин выбора данных — их близость к нашей привычной социо-гуманиторной сфере (сюда относятся и отношения с клиентами), другая — большая популярность набора: так в случае непредвиденных осложнений мы скорее найдем помощь в интернете.

*Скачивание данных:*

```{r data_download}
if (!file.exists('data/bank-additional-full.csv')) {
  if (!file.exists('data/bank-additional.zip')) {
    if (!dir.exists('data')) dir.create('data')
    download.file(
      'http://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip',
      destfile = 'data/bank-additional.zip'
    )
  }
  unzip(
    'data/bank-additional.zip',
    files = c(
      'bank-additional/bank-additional-full.csv',
      'bank-additional/bank-additional-names.txt'
    ),
    exdir = 'data',
    junkpaths = TRUE
  )
}
```

### Описание

Набор данных создан для задач классификации. Каждое наблюдение описывает один сеанс переговоров с клиентом. Зависимая переменная `y` — открыл ли срочный депозитный вклад в банке. Признаковое пространство данных содержит информацию о времени разговора, экономические и демографические характеристики клиента, а так же (в расширенном наборе данных) несколько важных экономических индексов по стране на момент разговора. Полное описание переменных можно посмотреть на [странице](http://archive.ics.uci.edu/ml/datasets/Bank+Marketing) набора на сайте Калифорнийского университета в Ирвайне или в файле `data/bank-additional-names.txt`.

### Предобработка и разведочный анализ

Методом проб и ошибок установлено, что csv-файл содержит редкое сочетание разделителя — точки с запятой и разделителя дробной части — точки.

*Чтение данных и просмотр:*

```{r data_load, message=FALSE}
data <- read_delim(
  'data/bank-additional-full.csv',
  delim = ';',
  locale = locale(decimal_mark = '.')
)
glimpse(data)
summary(data)
```

#### Предобработка

Согласно описанию данных, все переменные с буквенными данными — категории (факторы), причем некоторые (например, образование, для прочих это не принципиально) —упорядоченные. Использование категорий может быть важным для дальнейшего анализа и визуализации. Также в переменной `pdays` (количество дней, прошедших со  дня предыдущего разговора с клиентом) пропущенное значение (точнее, неприменимое к данным наблюдениям) закодировано как 999. Также говорится, что переменную `duration` (продолжительность разговора в секундах) лучше исключить из анализа, так как она слишком сильно влияет на зависимую переменную при значении равном 0.

*Перекодировка переменных:*

```{r data_preprocess}
data <- data %>%
  # mutate(
  #   education_info = if_else(
  #     education == 'unknown',
  #     'unknown',
  #     'known'
  #   )
  # ) %>%
  # mutate(
  #   education = if_else(
  #     education != 'unknown',
  #     education,
  #     NA_character_
  #     # Иначе ошибка: несовпадение классов
  #   )
  # ) %>%
  # 999 means client was not previously contacted
  # распространенная метка для пропущенных значений, например, в SPSS
  # i.e. previous == 0 & poutcome == "nonexistent"
  # see: tapply(data$pdays, data$poutcome, mean)
  mutate(
    pdays = if_else(
      pdays == 999,
      NaN,
      pdays
    )
  ) %>%
  mutate_if(is.character, as.factor) %>%
  # mutate(
  #   education = factor(
  #     education,
  #     ordered = TRUE,
  #     levels = c(
  #       'illiterate',
  #       'basic.4y',
  #       'basic.6y',
  #       'basic.9y',
  #       'high.school',
  #       'professional.course',
  #       'university.degree'
  #     )
  #   )
  # ) %>%
  # This input should only be included for benchmark purposes
  # and should be discarded if
  # the intention is to have a realistic predictive model
  select(-duration) %>%
  # Reorder the levels of the dependent variable
  # so that model evaluation and interpretation can be more straightforward
  mutate(y = relevel(y, 'yes'))
```

Таким образом, мы создали пропущенные значения там, где их не было. Однако пропущенная информация содержится в других переменных, что хорошо именно для классификации методом деревьев.

#### Поиск выбросов

С помощью пакета `dlookr` найдем переменные с выбросами:

```{r data_outlier}
dlookr::describe(data)

dlookr::find_outliers(data, rate = TRUE, index = FALSE)
```

Что делать с выбросами в перечисленных переменных:

* `age` (возраст клиента):
    + **Возможная причина:** нормальная ситуация для данных, где представлены один или несколькр долгожителей;
    + **Решение:** оставить;
* `campaign` (количество контактов с клиентом в рамках текущей телемаркетинговой кампании), `pdays` (Количество дней с последних переговоров с клиентом в рамках *предыдущей* кампании), `previous` (количество контактов с данным клиентом *до* настоящей кампании):
    + **Возможная причина:** есть какое-то количество клиентов с аномально большим количеством контактов; скорее всего, ничего особенного в этом нет;
    + **Решение:** проверить влияние на зависимую переменную.

Проверка влияния выбросов на зависимую переменную (в соответствии с [инструкцией](https://cran.r-project.org/web/packages/dlookr/vignettes/EDA.html) по пакету `dlookr`):

```{r data_outlier_inflence, warning=FALSE}
data_target <- dlookr::target_by(data, y)

dlookr::relate(data_target, campaign)
dlookr::relate(data_target, pdays)
dlookr::relate(data_target, previous)

rm(data_target)
```

Сопоставление числовых данных со значением зависимой переменной, как и диапазон значений самих переменных, показывают, что удаления выбросов, скорее всего, не требуется.

## Анализ

*Разбиение на тренироволчный и тестовый наборы:*

```{r analysis_split}
data$id = 1:nrow(data)

set.seed(1111)
data_train <- data %>%
  group_by(y) %>%
  sample_frac(.7) %>%
  ungroup()
summary(data_train)

data_test <- data %>%
  anti_join(data_train, by = 'id') %>%
  select(-id)
# Избавляемся от колонки id, которая является лишней при обучении модели
data_train <- select(data_train, -id)
data <- select(data, -id)

# Убедимся, что разбиение корректно
nrow(data_train) + nrow(data_test) == nrow(data)
```

### Функции оценки моделей

В начале создадим вручную несколько функций для оценки моделей. Для ориентира приводится таблица — шаблон матрицы ошибок

```{r confusion_matrix, echo=FALSE}
t <- matrix(
  c('TP', 'FN', 'FP', 'TN'),
  ncol = 2,
  dimnames = list(
    Predicted = c('Yes', 'No'),
    Actual    = c('Yes', 'No')
  )
)

print(t, comment = FALSE, quote = FALSE, print.gap = 4)
```


```{r model_evaluation}
# Все три элементарные функции принимают на вход
# векторы предсказанных (predicted) и истинных (reference) значений
# после чего строят матрицу ошибок для вычисления показателей

.cmatrix <- function(predicted, reference, print.tab) {
  tab <- table(Predicted = predicted, Actual = reference)
  if (print.tab) print(tab, comment = FALSE, quote = FALSE, print.gap = 4)
  assign('TP', tab[1, 1], pos = parent.frame())
  assign('FP', tab[1, 2], pos = parent.frame())
  assign('FN', tab[2, 1], pos = parent.frame())
  assign('TN', tab[2, 2], pos = parent.frame())
}

accuracy <- function(predicted, reference, print.tab = TRUE) {
  .cmatrix(predicted, reference, print.tab)
  (TP + TN) / (TP + FP + FN + TN)
}

precision <- function(predicted, reference, print.tab = TRUE) {
  .cmatrix(predicted, reference, print.tab)
  TP / (TP + FP)
}

recall <- function(predicted, reference, print.tab = TRUE) {
  .cmatrix(predicted, reference, print.tab)
  TP / (TP + FN)
}

specificity <- function(predicted, reference, print.tab = TRUE) {
  .cmatrix(predicted, reference, print.tab)
  TN / (TN + FP)
}

# Единая функция для расчета всех индексов + показатель F1
evaluate_model <- function(predicted, reference, print.tab = TRUE) {
  if (print.tab) cat('\nConfusion matrix:\n\n')
  .cmatrix(predicted, reference, print.tab)
  if (print.tab) cat('\n\nModel scores:\n\n')
  return(
    c(
      Accuracy    = (TP + TN) / (TP + FP + FN + TN),
      Precision   = TP / (TP + FP),
      Recall      = TP / (TP + FN),
      Specificity = TN / (TN + FP),
      'F1 Score'  = 2*TP / (2*TP + FP + FN)
    )
  )
}
```

Протестируем функции на синтезированных данных:

```{r model_evaluation_test}
pred <- sample(data$y, length(data$y))

accuracy(data$y, data$y)
accuracy(pred, data$y)
precision(data$y, data$y, print.tab = FALSE)
precision(pred, data$y, print.tab = FALSE)
recall(data$y, data$y, print.tab = FALSE)
recall(pred, data$y, print.tab = FALSE)
specificity(pred, data$y, print.tab = FALSE)

evaluate_model(pred, data$y, print.tab = FALSE)
```

### Деревья классификации

Для анализа мы воспользуемся функцией построения деревьев классификации из пакета `rpart`.

#### 1. Базовая модель

```{r tree_01_default}
model <- rpart(
  y ~ .,
  data = data_train,
  xval = 30
)
fancyRpartPlot(model)
pred <- predict(model, data_test, type = 'class')
evaluate_model(predicted = pred, reference = data_test$y)
```

Модель имеет очень низкий показатель F1, очень низкую полноту и неудовлетворительную точность, зато очень высокую специфичность, т. е. способность правильно предсказывать отрицательный результат. Вероятно, это связано с низкой частотностью позитивных результатов в выборке.

В таких случаях советуют корректировать алгоритм одним из таких путей:

1. Повысить априорную вероятность редкого исхода
2. Задать в матрице потерь более высокое значение для ложно-отрицательной классификации
3. Стратифицированная выборка с повышением вероятности редкого исхода.
4. Присвоение большего веса наблюдениям с редким классом.

Также предсказательную мощность можно повысить, если разрешить модели «вырастить» большое разветвленное дерево, а затем сократить его прунингом. Для большего ветвления можно сократить минимальное количество наблюдений в конечных листьях или «освободить» критерий сложности `complexity parameter`.

Кроме того, уберем из пространства признаков заведомо бессмысленные (хотя и мощные, как покажет разведывательный анализ данных `dlookr::eda_report()`) предикторы: месяц и день недели.

```{r data_reduce}
drop_cols <- c('month', 'day_of_week')
data_train <- select(data_train, -drop_cols)
data_test <- select(data_test, -drop_cols)
```

#### 2. Априорная вероятность

```{r tree_02_priors}
model <- rpart(
  y ~ .,
  data = data_train,
  xval = 30,
  parms = list(prior = c(.25, .75))
)
fancyRpartPlot(model)
pred <- predict(model, data_test, type = 'class')
evaluate_model(predicted = pred, reference = data_test$y)
```

Комплексный показатель качества модели стал намного выше, а специфичность сократилась из-за повышения вероятности классифицировать наблюдение как положительное.

#### 3. Матрица потерь

```{r tree_03_priors_loss}
lossmatrix <- matrix(c(0, 3, 5, 0))
model <- rpart(
  y ~ .,
  data = data_train,
  xval = 30,
  parms = list(
    prior = c(.25, .75),
    loss  = lossmatrix
  )
)
fancyRpartPlot(model)
pred <- predict(model, data_test, type = 'class')
evaluate_model(predicted = pred, reference = data_test$y)
```

Штраф за ложноотрицательную классификацию может радикально повысить полноту предсказаний за счет остальных показатель качества.

#### 4. Альтернативная выборка

```{r tree_04_biased-sample}
set.seed(1111)
data_train_b <- data_train %>%
  group_by(y) %>%
  group_split() %>%
  map2_df(c(2000, 4000), ~ sample_n(.x, size = .y))

model <- rpart(
  y ~ .,
  data = data_train_b,
  xval = 30
)
fancyRpartPlot(model)
pred <- predict(model, data_test, type = 'class')
evaluate_model(predicted = pred, reference = data_test$y)
```

Стратифицированная выборка также повышает полноту классификации, но не ее общее качество.

#### 5. Вес для редкого класса

```{r tree_05_weights}
wghts <- ifelse(data_train$y == 'yes', 5, 1)
model <- rpart(
  y ~ .,
  data = data_train,
  weights = wghts,
  xval = 30
)
fancyRpartPlot(model)
pred <- predict(model, data_test, type = 'class')
evaluate_model(predicted = pred, reference = data_test$y)
```

Снова нет улучшения. Как и предыдущие способы, повышение веса наблюдений с редким классом повышает априорную вероятность и, следовательно, полноту классификации по этому классу.

#### 6. Прунинг

Воспользуемся советом из статьи на [GormAnalysis](https://www.gormanalysis.com/blog/decision-trees-in-r-using-rpart/):

> As a rule of thumb, it’s best to prune a decision tree using the cp of smallest tree that is within one standard deviation of the tree with the smallest xerror.

```{r tree_06_pruning}
lossmatrix <- matrix(c(0, 3, 5, 0))
model <- rpart(
  y ~ .,
  data = data_train,
  xval = 30,
  parms = list(
    prior = c(.25, .75),
    loss  = lossmatrix
  ),
  control = list(
    cp = -1
  )
)
```

Можно посмотреть важность переменных для классификации:

```{r variable_importance}
model$variable.importance
```

Наиболее важными для модели являются макроэкономические показатели на момент переговоров: **количество сотрудников** (более точного определения показателя найти не удалось), **индекс EURIBOR** — ставка, по которой банки одалживают средства на межбанковском рынке Европейских стран, **Индекс потребительской уверенности**, **Коэффициент вариации занятости** (показатель текучести кадров по экономике в целом) и др.

```{r tree_06-1_pruning-prune}
(cps <- model$cptable %>%
  as_tibble() %>%
  set_names(c('CP', 'nsplit', 'rel_error', 'xerror', 'xstd')))

(cp_fit <- cps %>%
  filter(
    xerror <= (
      first(xerror, order_by = xerror) + first(xstd, order_by = xerror)
    ),
    nsplit > 1
  ) %>%
  arrange(nsplit) %>%
  slice(1) %>%
  pull(CP))

model <- prune(model, cp = cp_fit)

fancyRpartPlot(model)
pred <- predict(model, data_test, type = 'class')
evaluate_model(predicted = pred, reference = data_test$y)
```

Пока это наилучший результат, но и его нельзя считать удовлетворительным.

```{r}
best_so_far <- model
```

#### 7. Мультиколлинеарность

Наконец, можно попытаться избавиться от сильно коррелирующих друг с другом и потому избыточных переменных — экономических показателей, кроме текучести рабочей силы:

```{r variables_cor}
dlookr::correlate(select(data, 15:19))
```

```{r tree_07_drop}
drop_cols <- c('nr.employed', 'cons.price.idx', 'euribor3m', 'cons.conf.idx')
data_train_d <- select(data_train, -drop_cols)
data_test_d <- select(data_test, -drop_cols)

wghts <- ifelse(data_train_d$y == 'yes', 5, 1)
model <- rpart(
  y ~ .,
  data = data_train_d,
  weights = wghts,
  xval = 30
)
fancyRpartPlot(model)
pred <- predict(model, data_test_d, type = 'class')
evaluate_model(predicted = pred, reference = data_test_d$y)
```

Результат уступает лучшему из уже достигнутых.

## Заключение

Вероятно, данные сложно поддаются классификации с использованием решающих деревьев. Также сказывается отсутствие достаточных знаний и опыта. Предполагаем, что при реальном использовании подобной модели следовало бы максимизировать именно полноту классификации, если выгода от привлеченного депозита превышает стоимость неудачных звонков.

Сами авторы набора данных в своей [статье](http://media.salford-systems.com/video/tutorial/2015/targeted_marketing.pdf) не указывают решающие деревья в качестве лучшего алгоритма классификации их данных. Кстати, в оригинальном материале также использовался пакет `rpart`, а основной метрикой качества была **AUC**, которая для метода решающих деревьев оказалась равна ≈ 0,757. Нам почти удалось повторить этот результат:

```{r model_auc}
pred <- predict(best_so_far, data_test, type = 'class')
ModelMetrics::auc(actual = data_test$y, predicted = pred)
```