---
title: "Homework_A/B testing - проблема подглядывания"
author: "Oksana Laputskaya"
date: '13 декабря 2019 г '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Homework until 21.12.19

* Для иллюстрации проблемы подглядывания сэмулируйте 2 биномиальных распределения, задайте произвольный уровень значимости, планируемый размер числа наблюдений и минимально обнаруживаемый эффект. 

* Предполагая, что во время нашего тестирования в каждый момент времени мы получаем определенные значения для групп A и B, постройте график, иллюстрирующий проблему подглядывания. 

* На графике должны быть отображены точки, когда можно обнаружить один из вариантов лучше другого, при этом планируемое число наблюдений еще не достигнуто.

* Сделайте выводы.

```{r libraries_load, message=FALSE, warning=FALSE}
required_packages <- c(
  'broom', 'purrr', 'tidyr', 'dplyr', 'ggplot2'
)
if (!all(required_packages %in% installed.packages())) {
  install.packages(setdiff(required_packages, installed.packages()))
}

library(purrr)
library(tidyr)
library(dplyr)
library(ggplot2)

name <- function(x) { # Более короткий способ получить название переменной
  deparse(substitute(x))
}
```

*Мы попробуем воспроизвести поведение «заинтересованного» исследователя, который стремится обнаружить эффект, даже если данные к этому не располагают. Он также выбирает низкий уровень значимости в 90%. На диаграмме мы увидим, в какой момент он мог бы остановить наблюдение, чтобы получить желаемый результат.*

## Генерация данных

```{r data_generation}
N <- 200  # Для обеих групп
p <- .47  # Для обеих групп

set.seed(191222)
A <- factor(
  sample(
    c('Agree', 'Disagree'),
    size = N,
    replace = TRUE,
    prob = c(p, 1-p)
  )
)
B <- factor(
  sample(
    c('Agree', 'Disagree'),
    size = N,
    replace = TRUE,
    prob = c(p, 1-p)
  )
)

c(mean(A == 'Agree'), mean(B == 'Agree')) # Какие получились пропорции

# Основная таблица данных:
df <- map2(
  list(A, B),
  list(name(A), name(B)),
  ~ tibble(group = .y, response = .x)
) %>%
  bind_rows() %>%
  mutate(
    group = factor(group)
  ) %>%
  group_by(group) %>%
  mutate(
    trial = 1:n(),
    p_hat = cummean(response == 'Agree')
  )
```

## Оценка результатов генерации

*Можно оценить итоговое различие между выборками групп, воспользовавшись готовыми функциями статистических тестов в R. Как видим, оно не значимо:*

```{r overall_test}
fisher.test(A, B, conf.level = .9) # Точный тест Фишера

prop.test(                         # Кажется, хи-квадрат?
  rbind(A = table(A), B = table(B)),
  conf.level = .9,
  correct = FALSE
) 
```

*Для нашей симуляции напишем свою функцию теста гипотезы на равенство двух пропорций. Во-первых, так интереснее, во-вторых, его легче вписать в датафрейм для визуализации, хотя с тем же успехом можно было использовать `broom::tidy(prop.test(x, n))`.*

```{r tidy_test_function}
tidy_prop_test <- function(
  .tbl = NULL,
  # Некрасиво, но пытаемся максимально угадывать аргументы
  .cols = if (!is.null(.tbl)) which(sapply(.tbl, is.factor))[1:2] else NULL,
  x = NULL,
  y = NULL,
  # Выводим значения аргументов из данных
  reference = max(
    getElement(levels(x), 1),
    getElement(levels(.tbl[[.cols[1]]]), 1)
  ),
  null_value = 0,
  alternative = c('two tailed', 'less', 'greater'),
  alpha = 0.95
) {
  if ((is.null(x) | is.null(y)) & !is.null(.tbl)) {
    .tbl <- .tbl[, .cols]
    x <- .tbl[[1]]
    y <- .tbl[[2]]
  }
  p1_hat <- mean(x == reference)
  p2_hat <- mean(y == reference)
  n1 <- length(x)
  n2 <- length(y)
  
  # Если при нулевой гипотезе p1 - p2 = 0, используется объединенная пропорция
  if (null_value == 0) {
    p_pool  <- (p1_hat*n1 + p2_hat*n2) / (n1 + n2)
    sf_cond <- c(p_pool*n1, p_pool*n2, (1-p_pool)*n1, (1-p_pool)*n2)
    SE <- sqrt(
      ((p_pool * (1-p_pool)) / n1) + ((p_pool * (1-p_pool)) / n2)
    )
  } else {
    sf_cond <- c(p1_hat*n1, p2_hat*n2, (1-p1_hat)*n1, (1-p2_hat)*n2)
    SE <- sqrt(
      ((p1_hat * (1-p1_hat)) / n1) + ((p2_hat * (1-p2_hat)) / n2)
    )
  }
  
  # Проверка условия
  sf_cond <- !(any(sf_cond < 10))
  if (!sf_cond) {
    warning(
      'Test results are unreliable: the success-failure condition is not met',
      call. = FALSE
    )
  }
  
  # Проверка гипотезы
  estimate <- p1_hat - p2_hat
  Z <- (abs(estimate) - null_value) / SE
  alternative <- match.arg(alternative)
  p_value <- switch(
    alternative,
    'two tailed' = 1 - pnorm(Z) + pnorm(-Z),
    'less'       = pnorm(-Z),
    'greater'    = pnorm(Z, lower.tail = FALSE)
  )
  
  # Доверительный интервал
  z_star <- qnorm(1 - (1 - alpha)/2)
  ME <- z_star * SE
  ci_lower <- estimate - ME
  ci_upper <- estimate + ME
  
  # Возвращаем в виде таблицы данных
  return(
    data.frame(
      p1_hat,
      p2_hat,
      diff_hat = estimate,
      sf_cond,
      se = SE,
      conf_level = alpha,
      ci_lower,
      ci_upper,
      null_value,
      statistic = Z,
      alternative,
      p_value
    )
  )
}
```

*Посмотрим, как результаты нашей функции согласуются с уже реализованным тестом:*

```{r overall_test_tidy}
tidy_prop_test(x = A, y = B, alpha = .9)

broom::tidy(
  prop.test(
    rbind(A = table(A), B = table(B)),
    conf.level = .9,
    correct = FALSE
  )
)
```

## Симуляция подглядывания

```{r peeking_simulation, warning=FALSE}
df_wide <- df %>%
  ungroup() %>%
  pivot_wider(id_cols = trial, names_from = group, values_from = response)

df_wide %>% select(-trial) %>% summarise_all(~ mean(. == 'Agree')) # Знакомо

df_wide_test <- map(
  df_wide$trial,
  ~ slice(df_wide, 1:.x)
) %>%
  map_df(tidy_prop_test, alpha = .9) %>%
  as_tibble()
df_wide <- bind_cols(df_wide, df_wide_test)
```

*↑Здесь наш исследователь проверяет гипотезу после испытания каждой «пары», рассчитывая статистику для наблюдений от первого до текущего. В какой-то момент он получает результат↓*

```{r peeking_success}
df_wide %>%
  select(1:5, ci_lower, ci_upper, p_value) %>%
  arrange(p_value)
```

## Визуализация

```{r peeking_plot}
# Датафрейм специально для диаграммы:
# Две переменные для границ заливки на промежутках со статистически значимыми
# ... различиями:
df_wide_plot <- df_wide %>%
  filter(!is.na(p_value) & sf_cond) %>%
  mutate(
    lowest  = ifelse(p_value > .1, 0, if_else(p1_hat < p2_hat, p1_hat, p2_hat)),
    highest = ifelse(p_value > .1, 0, if_else(p1_hat > p2_hat, p1_hat, p2_hat))
  )

min_cases <- min(df_wide_plot$trial)
df <- slice(df, min_cases:n())

ggplot(
  df,
  aes(x = trial, colour = group)
) +
  geom_line(aes(y = p_hat)) +
  geom_ribbon(
    data = df_wide_plot,
    aes(
      x = trial,
      ymin = lowest,
      ymax = highest
    ),
    inherit.aes = FALSE,
    fill = 'navy',
    alpha = .3
  ) +
  scale_x_continuous('№ испытания', breaks = seq(0, 200, 20)) +
  scale_y_continuous('Пропорции по группам', limits = c(.3, .6)) +
  scale_colour_manual('Группа', values = c('red3', 'navy')) +
  ggtitle('Подглядывание и ложноположительные выводы') +
  annotate('text', x = 125, y = .45, label = '<-- p < 0.10', hjust = 0) +
  theme_minimal() +
  theme(plot.margin = margin(4, 0, 0, 4))
```

*Как видим, у исследователя была возможность остановить испытания на промежутке от 110 до 120, когда доля положительных ответов в группе ***B** *превышало долю положительных ответов в группе ***A** *за пределами статистической погорешности, и объявить результаты эксперимента значимыми.*