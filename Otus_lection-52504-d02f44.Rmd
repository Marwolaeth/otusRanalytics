---
title: "A/B Testing"
author: "Oksana Laputskaya"
date: '11 декабря 2019 г '
output: html_document

---


## Быстрые вычисления значения для A / B тестов в R 


**Маршрут вебинара**

> Понятийный аппарат А/В тестирования

> Алгоритм bootstrap 

> Peeking problem

**Цели**

После занятия вы сможете

1. Оценивать целесообразность проведения A/B тестирования тем или иным методом
2. Проводить собственное тестирование
3. Интерпретировать результаты


**Смысл**




### Введение 

Классический подход к А/B тестированию.
При решении вероятностных задач часто приходится сталкиваться с ситуациями, в которых одно и тоже испытание повторяется многократно и исход каждого испытания независим от исходов других. Такой эксперимент еще называется схемой повторных независимых испытаний или схемой Бернулли.

Давайте кратко рассмотрим очень важную и распространенную экспериментальную проблему: проверить, является ли разница в показателях успешности двух биномиальных экспериментов статистически значимой. Это может возникнуть в ситуациях A / B-тестирования, таких как интернет-реклама, продажи и производство. 
A / B-тестирование - это использование экспериментального проекта и статистики для сравнения двух или более вариантов дизайна.



### Bootstrap

__Bootstrap__ - это метод вывода о популяции с использованием выборочных данных. Брэдли Эфрон впервые представил его в этой статье в 1979 году. Bootstrap опирается на выборку с заменой выборочных данных. Этот метод может быть использован для оценки стандартной ошибки любой статистики и получения доверительного интервала (CI) для нее. Bootstrap особенно полезен, когда CI не имеет закрытой формы или имеет очень сложную форму. 
Предположим, у нас есть выборка из n элементов: X = {x1, x2,…, xn}, и нас интересует CI для некоторой статистики T = t (X). 
Основа начальной загрузки проста. Мы просто повторяем R раз по следующей схеме: для i-го повторения выборка с заменой n элементов из доступной выборки (некоторые из них будут выбраны более одного раза). 
Назовите этот новый пример i-го примера начальной загрузки, Xi, и рассчитайте желаемую статистику Ti = t (Xi). 
В результате мы получим R значений нашей статистики: T1, T2,…, TR. Мы называем их реализациями начальной загрузки T или распределением начальной загрузки T. Основываясь на этом, мы можем вычислить CI для T. Есть несколько способов сделать это. Взятие процентилей кажется самым легким.


Бутстрэп-процедура состоит в многократном извлечении подвыборок из эмпирического распределения. Для оценки любых параметров можно сформировать тысячи повторных бутстрэп-выборок (обычно 500-10 000), каждая из которых содержит 2/3 значений исходной выборки. Используя подвыборки, мы можем построить распределение любой статистики, даже для непараметрических данных.

![наглядно](https://static.tildacdn.com/tild3932-3531-4031-a435-366130333531/noroot.jpg)

**Алгоритм расчета доверительного интервала при помощи бутстрэп:**
**Алгоритм:**

1. Выберите 10 наблюдений из выборки. Отбор осуществляется с возвратом, то есть некоторые наблюдения могут быть выбраны несколько раз, а некоторые могут остаться невыбранными.
2. Вычислите среднее (либо любую другую статистику) для полученного набора из 10 значений.
3. Повторите шаги 500 - 10 000 раз.
4. Отсортируйте тысячу выборочных средних по возрастанию.
5. Найдите средние, которые представляют собой 2.5 и 97.5 процентили. В данном примере это 25-е число с начала и с конца. Два выбранных значения и будут границами 95%-го доверительного интервала.


### Проблема подглядывания

При дизайне, запуске и анализе A/B тестов можно допустить много ошибок, но одна из них особенно коварна. Эта ошибка – побочный эффект проверки результатов A/B теста c готовностью действовать на их основе до его окончания. Ее называют «Peeking problem» или «Проблема подглядывания».

**Классический алгоритм проверки статистической значимости:**

1. Собираются данные для версии A и B.
2. Делается предположение, что тестовые группы между собой не отличаются.
3. В рамках предположения идентичности групп считается, какова вероятность получить наблюдаемую в эксперименте или большую разницу между группами. Такое значение называют p-value.
4. Если p-value меньше определенного порогового значения (обычно 5%), то изначальное предположение об идентичности тестовой и контрольной группы отвергается. В этом случае можно с высокой степенью уверенности утверждать, что наблюдаемая разница между группами значима (связана с их различиями, а не случайностью).
5. Если p-value больше порогового значения, то тестируемые версии на основе собранных данных неразличимы. При этом в реальности между ними как может быть различие, которое мы просто не выявили, так его может и не быть. Мы не знаем.

Применение стандартных критериев в рамках частотного подхода к статистике (Хи-квадрат, критерий Стюдента), которые используются для расчета p-value и статистической значимости, требуют выполнения различных условий. Например, многие критерии подразумевают нормальное распределение изучаемой величины.

Но есть еще одно важное условие, о существовании которого многие забывают: **размер выборки для эксперимента должен быть определен заранее.**

Вы должны заранее решить, сколько наблюдений хотите собрать. Потом посчитать результаты и принять решение. Если вдруг выявить значимую разницу на собранном количестве данных не получилось, то продолжать эксперимент с целью сбора дополнительных наблюдений нельзя. Можно только запустить тест заново.

Описанная логика звучит странно в контексте A/B тестов в интернете, где можно смотреть на результаты в режиме реального времени, где добавление новых пользователей в эксперимент ничего не стоит.

Дело в том, что используемый для A/B тестов математический аппарат в рамках частотного подхода к статистике разрабатывался задолго до появления интернета. Тогда большинство прикладных задач подразумевало фиксированный и заранее определенный размер выборки для проверки гипотезы.

Интернет поменял парадигму A/B тестирования. Вместо выбора фиксированного размера выборки перед запуском эксперимента большинство предпочитают собирать данные, пока разница между тестом и контролем не станет значимой. Следствием такого изменения в процедуре проведения экспериментов стало то, что расчеты p-value старыми способами перестали работать. Реальное p-value при регулярной проверке результатов теста становится намного больше, чем то p-value, что вы получаете, используя обычные статистические критерии, которые при такой процедуре перестают работать.


![ПРАВИЛЬНО ](https://gopractice.ru/wp-content/uploads/2018/07/2.png)

Проблема подглядывания проявляется, когда вы проверяете промежуточные результаты с готовностью принять решение: раскатить одну из версий, если различие между тестом и контролем окажется значимым. Если вы зафиксировали размер выборки и просто наблюдаете за результатами в процессе набора наблюдений (и ничего не делаете на их основе), а потом принимаете решение, когда набралось нужное количество данных, то никаких проблем не возникает.

![НЕПРАВИЛЬНО](https://gopractice.ru/wp-content/uploads/2018/07/3.png)

###Практика

1.A/B тест

#### 1. Анализ конверсии

**Задание:**

Было принято решение провести А/B тестирование в игре, одной группе пользователей показывали рекламу как обычно, другой не показывали вообще, и после этого были получены результаты, представленные в таблице ниже. 

| group         |   Total New Users |   Paying Users |  Rate1 = Paying/Total       |
|---------------|-------------------|----------------|-----------------------------|
| A:with ads    | 18930             | 980            | 5.18%                       |
| B:without ads | 16180             | 420            | 2.60%                       |



Проверим является ли это различие статистически значимым, либо оно просто вызвано случайными колебаниями.

Для начала мы предполагаем, что события "Пользователь оплатил" и "Пользователь не оплатил" подчиняются Биноминальному распределению. Для группы "A" мы имеем биноминальное распределение с параметром "вероятность успеха" равным `r round(980/18930, 4)`, а для группы "B" - `r round(420/16180, 4)`  

Теперь нам необходимо проверить, какая из гипотез верна:  
* Нулевая гипотеза Н0 - конверсии равны.  
* Альтернативная гипотеза - конверсии не равны.  

Рассчитаем вероятность получить указанные в таблице результаты, при условии, что верна нулевая гипотеза.


```{r echo=T}
test <- binom.test(x=420, n=16180, p = 0.0518, conf.level = 0.99)
test$p.value
```
Мы видим, что эта вероятность практически равна нулю, что дает нам основание отвергнуть нулевую гипотезу о равенстве конверсий и заявить, что конверсии значимо различаются.

Рассчитаем 99%-доверительные интервалы для оценок наших конверсий.  
A:with ads

```{r echo=T}
binom.test(980, 18930, conf.level = 0.99)$conf.int
```

B:without ads

```{r echo=T}
binom.test(420, 16180, conf.level = 0.99)$conf.int
```

Мы видим, что доверительные интервалы не пересекаются, что еще раз подтверждает правильность результатов теста. И мы можем сказать, что в среднем вариант "A" конвертирует  в `2 (=5.18/2.6)` раза лучше, чем вариант "B", при этом доверительный интервал для данной оценки составляет `(1.6-2.5)`.

Выводы кратко: в рамках данного анализа мы рассчитали основные показатели воронки продаж для обоих вариантов и проверили статистическую значимость различий. По средней конверсии в первую продажу лучше отработал вариант с рекламой, но по среднему числу продаж на одного игрока лучше был вариант без рекламы.



#### 2. Bootstrap


```{r}
library(boot)
# Creating Function to obtain R-Squared from the data
r_squared <- function(formula, data, indices) {
val <- data[indices,] # selecting sample with boot 
fit <- lm(formula, data=val)
return(summary(fit)$r.square)
} 
# Performing 1500 replications with boot 
output <- boot(data=mtcars, statistic=r_squared, 
R=1500, formula=mpg~wt+disp)
# Plotting the output
output 
plot(output)
# Obtaining a confidence interval of 95%
boot.ci(output, type="bca")


```
boot.ci может возвращать 5 типов доверительных интервалов (агрумент type):

* norm (Normal Representation)
* Basic 
* stud (studentized)
* perc (percentile)
* Bca (bias-corrected, accelerated)

Чтобы понять различные типы ДИ в алгоритме, давайте рассмотрим некоторые важные нотации: 

Среднее значение реализаций начальной загрузки представлено как t by, что является нашей оценкой начальной загрузки. 
Значение статистики в нашем наборе данных - t0. 
Стандартная ошибка в нашей оценке начальной загрузки обозначается как se⋆. 
Начальная оценка b = t⋆ - t0, где b - наше смещение. 
Уровень достоверности обозначается через α. 
Квантиль 1 − α2 стандартного нормального распределения равна zα. 
Α-процентиль распределения реализаций бутстрапа представлен θα. 

Теперь мы рассмотрим различные ДИ:

1. Процентный ДИ принимает соответствующие процентили. Используя приведенные выше обозначения, процентиль CI записывается так:

![](https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2018/01/Percentile-CI.jpg)

2. Нормальный ДИ. В случае bootstrap мы модифицируем доверитеельный интервал Уайльда для смещения. В этом случае нормальный ДИ становится
![](https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2018/01/Normal-CI.jpg)

3. Базовое

![](https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2018/01/Basic-CI.jpg)

4. BCαCI
BCα CI обозначает исправление смещения. Ускорение в названии метода, требует определенного процентиля реализации бутстрапа. Иногда эти процентили могут быть выбросами и, следовательно, экстремальными по своей природе. В этих сценариях BCα может быть весьма нестабильным.


**Методы bootstraping в R:**

1. Остатки Сначала мы загружаем остатки. Затем создайте набор новых зависимых переменных. После этого мы используем эти зависимые переменные для формирования загрузочной выборки. 
2. Начальные пары Он включает в себя выборку пар зависимой и независимой переменной. Между этими двумя методами второй метод оказался более надежным. 


**Когда использовать Bootstrap в R?**

Он используется для включения вывода статистики по интересам. Это важно, когда истинное распределение этой статистики неизвестно. Например: В случае линейной модели, если аналитик не хочет тратить время на выведение уравнений, то можно получить стандартные ошибки и доверительные интервалы, не загружая никаких доп. пакетов. 

**Когда bootstrap бесполезен?**

Это дает набор сценариев, когда бутстреп может потерпеть неудачу: 

1. Для небольших размеров выборки менее 10, бутстреп неприменим.
2. При оценке экстремальных значений. 
3. Во время нестабильных процессов авторегрессии.

### Домашнее задание к 20.12
- напишите функцию собственной реализации бутстрэпа и с помощью нее рассчитйте границы доверительного интервала для Примера 1

### Полезные материалы:

[Избегание проблемы подглядывания](http://elem.com/~btilly/ab-testing-multiple-looks/part1-rigorous.html#procedure)

[Качество системы A/B тестирования](https://habr.com/ru/company/hh/blog/321386/)

[A/A тестирование и когда оно может быть полезно](https://yagla.ru/blog/analitika/chto-takoe-aa-testirovanie-i-kak-ego-provesti/)

[Видео-курс Bootstraping in R](https://www.youtube.com/playlist?list=PLqzoL9-eJTNDp_bWyWBdw2ioA43B3dBrl)
